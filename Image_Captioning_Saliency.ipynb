{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb4e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_captioning_model\n",
    "from model_architecture import CNNtoRNN\n",
    "from gradcam import GradCAM\n",
    "import os\n",
    "from model import ConvNet\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from utils import visualize_cam, Normalize, print_examples\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from datetime import datetime\n",
    "from get_loader import get_loader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5915ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "40051\n",
      "404\n"
     ]
    }
   ],
   "source": [
    "preprocessing = transforms.Compose([\n",
    "            transforms.Resize((356,356)),\n",
    "            transforms.RandomCrop((299,299)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "        ])\n",
    "\n",
    "train_loader, val_loader, dataset = get_loader(\n",
    "        root_folder=\"flickr8k/Images\",\n",
    "        annotation_file=\"flickr8k/captions.txt\",\n",
    "        transform = preprocessing,\n",
    "        num_workers=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"dog.jpg\"\n",
    "image_path = \"images\\\\\" + file_name\n",
    "dog_image = Image.open(image_path)\n",
    "normalizer = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "dog_torch_img = torch.from_numpy(np.asarray(dog_image)).permute(2, 0, 1).unsqueeze(0).float().div(255).cuda()\n",
    "dog_torch_img = F.upsample(dog_torch_img, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "dog_norm_torch_img = normalizer(dog_torch_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
